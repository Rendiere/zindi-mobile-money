{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPOT Best Model\n",
    "\n",
    "Using the best model selected by TPOT, fine tune and perform some feature engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.models.tpot import get_best_model\n",
    "from src.data.utils import extract_targets, load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8_1</th>\n",
       "      <th>Q8_2</th>\n",
       "      <th>Q8_3</th>\n",
       "      <th>...</th>\n",
       "      <th>mm_total_withdrawals</th>\n",
       "      <th>mm_total_deposits</th>\n",
       "      <th>mm_wdraw_dep_ratio</th>\n",
       "      <th>mm_n_closest_10_km</th>\n",
       "      <th>region_distance</th>\n",
       "      <th>region</th>\n",
       "      <th>district_distance</th>\n",
       "      <th>district</th>\n",
       "      <th>ward_distance</th>\n",
       "      <th>ward</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5086</th>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.639220</td>\n",
       "      <td>Kigoma</td>\n",
       "      <td>24.600008</td>\n",
       "      <td>Kasulu</td>\n",
       "      <td>25.115583</td>\n",
       "      <td>Heru Ushingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>278.0</td>\n",
       "      <td>24.238709</td>\n",
       "      <td>Zanzibar</td>\n",
       "      <td>24.238709</td>\n",
       "      <td>Zanzibar</td>\n",
       "      <td>2.650153</td>\n",
       "      <td>Magogoni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>781.0</td>\n",
       "      <td>33.490434</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>1.700766</td>\n",
       "      <td>Morogoro Urban</td>\n",
       "      <td>0.332536</td>\n",
       "      <td>Mafiga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6729</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.880597</td>\n",
       "      <td>61.0</td>\n",
       "      <td>89.724488</td>\n",
       "      <td>Arusha</td>\n",
       "      <td>16.123696</td>\n",
       "      <td>Karatu</td>\n",
       "      <td>5.875602</td>\n",
       "      <td>Mto wa Mbu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.521739</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40.150180</td>\n",
       "      <td>Rukwa</td>\n",
       "      <td>29.264300</td>\n",
       "      <td>Nkansi</td>\n",
       "      <td>218.027062</td>\n",
       "      <td>Kaliua</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8_1  Q8_2  Q8_3  ...  mm_total_withdrawals  \\\n",
       "ID                                                  ...                         \n",
       "5086  98   2   3   1   1   2   2     0     0     0  ...                   4.0   \n",
       "1258  40   1   1   3   5   1   1     1     0     0  ...                  20.0   \n",
       "331   18   2   4   6   3   2   1     0     0     0  ...                  30.0   \n",
       "6729  50   1   1   3   1   1   1     0     0     0  ...                  59.0   \n",
       "8671  34   1   1   1   1   2   1     0     1     0  ...                  35.0   \n",
       "\n",
       "      mm_total_deposits  mm_wdraw_dep_ratio  mm_n_closest_10_km  \\\n",
       "ID                                                                \n",
       "5086                6.0            0.666667                12.0   \n",
       "1258               40.0            0.500000               278.0   \n",
       "331                36.0            0.833333               781.0   \n",
       "6729               67.0            0.880597                61.0   \n",
       "8671               23.0            1.521739                 2.0   \n",
       "\n",
       "      region_distance    region  district_distance        district  \\\n",
       "ID                                                                   \n",
       "5086        24.639220    Kigoma          24.600008          Kasulu   \n",
       "1258        24.238709  Zanzibar          24.238709        Zanzibar   \n",
       "331         33.490434  Morogoro           1.700766  Morogoro Urban   \n",
       "6729        89.724488    Arusha          16.123696          Karatu   \n",
       "8671        40.150180     Rukwa          29.264300          Nkansi   \n",
       "\n",
       "      ward_distance          ward  \n",
       "ID                                 \n",
       "5086      25.115583  Heru Ushingo  \n",
       "1258       2.650153      Magogoni  \n",
       "331        0.332536        Mafiga  \n",
       "6729       5.875602    Mto wa Mbu  \n",
       "8671     218.027062        Kaliua  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data = load_data()  \n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Encode region, district and ward\n",
    "\n",
    "Get the mean of each `mobile_money`, `savings`,  `borrowing` and `insurance` for each region, district and ward from the training set and replace these categories with those values in both training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_means(level):\n",
    "    \"\"\"\n",
    "    Get the target means for each category in \n",
    "    training data grouped by level\n",
    "    \"\"\"\n",
    "    grouped = train_data.groupby(level)\n",
    "\n",
    "    means = grouped.agg({'mobile_money':'mean', 'savings': 'mean', 'borrowing': 'mean', 'insurance': 'mean'})\n",
    "\n",
    "    # Add the count of people in that area\n",
    "    means['count'] = grouped.apply(len)\n",
    "    \n",
    "    # Rename the columns\n",
    "    means.columns = [f'{level}_{col}' for col in list(means)]\n",
    "    \n",
    "    return means\n",
    "\n",
    "def merge_means(df, means):\n",
    "    \"\"\"\n",
    "    Merge the train/test data with regional \n",
    "    target means and impute missing values\n",
    "    \"\"\"\n",
    "    \n",
    "    return df.merge(means, how='left', left_on=level, right_index=True).drop(level, axis=1).fillna(means.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ward_mobile_money     0.648527\n",
       "ward_savings          0.502264\n",
       "ward_borrowing        0.448394\n",
       "ward_insurance        0.167489\n",
       "ward_count           19.435616\n",
       "dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for level in ['region','district','ward']:\n",
    "    means = get_means(level=level)\n",
    "    train_data = merge_means(train_data, means)\n",
    "    test_data = merge_means(test_data, means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Best TPOT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('stackingestimator',\n",
       "                 StackingEstimator(estimator=GradientBoostingClassifier(criterion='friedman_mse',\n",
       "                                                                        init=None,\n",
       "                                                                        learning_rate=0.001,\n",
       "                                                                        loss='deviance',\n",
       "                                                                        max_depth=8,\n",
       "                                                                        max_features=0.1,\n",
       "                                                                        max_leaf_nodes=None,\n",
       "                                                                        min_impurity_decrease=0.0,\n",
       "                                                                        min_impurity_split=None,\n",
       "                                                                        min_samples_leaf=7,\n",
       "                                                                        min_samples_split=8,\n",
       "                                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                                        n_estima...\n",
       "                                                                        subsample=1.0,\n",
       "                                                                        tol=0.0001,\n",
       "                                                                        validation_fraction=0.1,\n",
       "                                                                        verbose=0,\n",
       "                                                                        warm_start=False))),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=0.5, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l1', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_best_model()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = extract_targets(train_data)\n",
    "X_test = test_data\n",
    "\n",
    "X_train.replace({'Yes': 1}, inplace=True)\n",
    "X_test.replace({'Yes': 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.762440437376498\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(cv_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=1020, style=ProgressStyle(descripâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: -0.7564270402642099\n",
      "Generation 2 - Current best internal CV score: -0.7529371870894669\n",
      "Generation 3 - Current best internal CV score: -0.747768070610554\n",
      "Generation 4 - Current best internal CV score: -0.747768070610554\n",
      "Generation 5 - Current best internal CV score: -0.747768070610554\n",
      "Generation 6 - Current best internal CV score: -0.747768070610554\n",
      "Generation 7 - Current best internal CV score: -0.7414832709363521\n",
      "Generation 8 - Current best internal CV score: -0.7414832709363521\n",
      "Generation 9 - Current best internal CV score: -0.7414832709363521\n",
      "Generation 10 - Current best internal CV score: -0.7414832709363521\n",
      "Generation 11 - Current best internal CV score: -0.7395425508735591\n",
      "Generation 12 - Current best internal CV score: -0.7395425508735591\n",
      "Generation 13 - Current best internal CV score: -0.7395425508735591\n",
      "Generation 14 - Current best internal CV score: -0.7395425508735591\n",
      "Generation 15 - Current best internal CV score: -0.7395425508735591\n",
      "Generation 16 - Current best internal CV score: -0.7395425508735591\n",
      "Generation 17 - Current best internal CV score: -0.739380407335174\n",
      "Generation 18 - Current best internal CV score: -0.739380407335174\n",
      "Generation 19 - Current best internal CV score: -0.739380407335174\n",
      "Generation 20 - Current best internal CV score: -0.739380407335174\n",
      "Generation 21 - Current best internal CV score: -0.7354425831344916\n",
      "Generation 22 - Current best internal CV score: -0.7354425831344916\n",
      "Generation 23 - Current best internal CV score: -0.7351315880906716\n",
      "Generation 24 - Current best internal CV score: -0.7351315880906716\n",
      "Generation 25 - Current best internal CV score: -0.7351315880906716\n",
      "Generation 26 - Current best internal CV score: -0.7351315880906716\n",
      "Generation 27 - Current best internal CV score: -0.7349237372626771\n",
      "Generation 28 - Current best internal CV score: -0.7349237372626771\n",
      "Generation 29 - Current best internal CV score: -0.7349237372626771\n",
      "Generation 30 - Current best internal CV score: -0.734534099495542\n",
      "Generation 31 - Current best internal CV score: -0.7345239988896319\n",
      "Generation 32 - Current best internal CV score: -0.7345239988896319\n",
      "Generation 33 - Current best internal CV score: -0.7345239988896319\n",
      "Generation 34 - Current best internal CV score: -0.734434532510925\n",
      "Generation 35 - Current best internal CV score: -0.734434532510925\n",
      "Generation 36 - Current best internal CV score: -0.7330416062390225\n",
      "Generation 37 - Current best internal CV score: -0.7330416062390225\n",
      "Generation 38 - Current best internal CV score: -0.7330416062390225\n",
      "Generation 39 - Current best internal CV score: -0.7328113343340186\n",
      "Generation 40 - Current best internal CV score: -0.7328113343340186\n",
      "Generation 41 - Current best internal CV score: -0.7328113343340186\n",
      "Generation 42 - Current best internal CV score: -0.7327764772752202\n",
      "Generation 43 - Current best internal CV score: -0.7327764772752202\n",
      "Generation 44 - Current best internal CV score: -0.7327764772752202\n",
      "Generation 45 - Current best internal CV score: -0.7327764772752202\n",
      "Generation 46 - Current best internal CV score: -0.7327432565076833\n",
      "Generation 47 - Current best internal CV score: -0.7327432565076833\n",
      "Generation 48 - Current best internal CV score: -0.7327432565076833\n",
      "Generation 49 - Current best internal CV score: -0.7327432565076833\n",
      "Generation 50 - Current best internal CV score: -0.7326581163228116\n",
      "\n",
      "Best pipeline: LogisticRegression(VarianceThreshold(MaxAbsScaler(DecisionTreeClassifier(GaussianNB(XGBClassifier(DecisionTreeClassifier(DecisionTreeClassifier(input_matrix, criterion=entropy, max_depth=2, min_samples_leaf=17, min_samples_split=4), criterion=entropy, max_depth=2, min_samples_leaf=19, min_samples_split=17), learning_rate=0.01, max_depth=2, min_child_weight=12, n_estimators=100, nthread=1, subsample=0.15000000000000002)), criterion=entropy, max_depth=2, min_samples_leaf=19, min_samples_split=17)), threshold=0.005), C=1.0, dual=False, penalty=l1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict=None, crossover_rate=0.1, cv=5,\n",
       "               disable_update_check=False, early_stop=None, generations=50,\n",
       "               max_eval_time_mins=5, max_time_mins=None, memory=None,\n",
       "               mutation_rate=0.9, n_jobs=-1, offspring_size=None,\n",
       "               periodic_checkpoint_folder=None, population_size=20,\n",
       "               random_state=None, scoring='neg_log_loss', subsample=1.0,\n",
       "               template='RandomTree', use_dask=False, verbosity=2,\n",
       "               warm_start=False)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tpot = TPOTClassifier(\n",
    "    generations=50, \n",
    "    population_size=20, \n",
    "    verbosity=2,\n",
    "    n_jobs=-1, \n",
    "    scoring='neg_log_loss'\n",
    ")\n",
    "tpot.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot.export('tpot_baseline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VarianceThreshold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-fae2f35e7f80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m test = LogisticRegression(\n\u001b[0;32m----> 2\u001b[0;31m     VarianceThreshold(\n\u001b[0m\u001b[1;32m      3\u001b[0m         MaxAbsScaler(\n\u001b[1;32m      4\u001b[0m             DecisionTreeClassifier(\n\u001b[1;32m      5\u001b[0m                 GaussianNB(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'VarianceThreshold' is not defined"
     ]
    }
   ],
   "source": [
    "LogisticRegression(\n",
    "    VarianceThreshold(\n",
    "        MaxAbsScaler(\n",
    "            DecisionTreeClassifier(\n",
    "                GaussianNB(\n",
    "                    XGBClassifier(\n",
    "                        DecisionTreeClassifier(\n",
    "                            DecisionTreeClassifier(input_matrix, \n",
    "                                                   DecisionTreeClassifier__criterion=entropy, \n",
    "                                                   DecisionTreeClassifier__max_depth=2, \n",
    "                                                   DecisionTreeClassifier__min_samples_leaf=17, \n",
    "                                                   DecisionTreeClassifier__min_samples_split=4), \n",
    "                            DecisionTreeClassifier__criterion=entropy, \n",
    "                            DecisionTreeClassifier__max_depth=2, \n",
    "                            DecisionTreeClassifier__min_samples_leaf=19, \n",
    "                            DecisionTreeClassifier__min_samples_split=17), \n",
    "                        XGBClassifier__learning_rate=0.01, \n",
    "                        XGBClassifier__max_depth=2, \n",
    "                        XGBClassifier__min_child_weight=12, \n",
    "                        XGBClassifier__n_estimators=100, \n",
    "                        XGBClassifier__nthread=1, \n",
    "                        XGBClassifier__subsample=0.15000000000000002)), \n",
    "                DecisionTreeClassifier__criterion=entropy, \n",
    "                DecisionTreeClassifier__max_depth=2, \n",
    "                DecisionTreeClassifier__min_samples_leaf=19, \n",
    "                DecisionTreeClassifier__min_samples_split=17)\n",
    "        ), \n",
    "        VarianceThreshold__threshold=0.005), \n",
    "    LogisticRegression__C=1.0, \n",
    "    LogisticRegression__dual=False, \n",
    "    LogisticRegression__penalty=l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get top 10 estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LogisticRegression(VarianceThreshold(MaxAbsScaler(DecisionTreeClassifier(GaussianNB(XGBClassifier(DecisionTreeClassifier(DecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=17, DecisionTreeClassifier__min_samples_split=4), DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=19, DecisionTreeClassifier__min_samples_split=17), XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=12, XGBClassifier__n_estimators=100, XGBClassifier__nthread=1, XGBClassifier__subsample=0.15000000000000002)), DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=19, DecisionTreeClassifier__min_samples_split=17)), VarianceThreshold__threshold=0.005), LogisticRegression__C=1.0, LogisticRegression__dual=False, LogisticRegression__penalty=l1)',\n",
       "  -0.7326581163228116),\n",
       " ('LogisticRegression(MaxAbsScaler(DecisionTreeClassifier(GaussianNB(XGBClassifier(DecisionTreeClassifier(DecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=17, DecisionTreeClassifier__min_samples_split=4), DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=19, DecisionTreeClassifier__min_samples_split=17), XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=12, XGBClassifier__n_estimators=100, XGBClassifier__nthread=1, XGBClassifier__subsample=0.15000000000000002)), DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=19, DecisionTreeClassifier__min_samples_split=17)), LogisticRegression__C=1.0, LogisticRegression__dual=False, LogisticRegression__penalty=l1)',\n",
       "  -0.7327432565076833),\n",
       " ('LogisticRegression(MaxAbsScaler(DecisionTreeClassifier(XGBClassifier(DecisionTreeClassifier(DecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=17, DecisionTreeClassifier__min_samples_split=4), DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=19, DecisionTreeClassifier__min_samples_split=17), XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=12, XGBClassifier__n_estimators=100, XGBClassifier__nthread=1, XGBClassifier__subsample=0.15000000000000002), DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=19, DecisionTreeClassifier__min_samples_split=17)), LogisticRegression__C=1.0, LogisticRegression__dual=False, LogisticRegression__penalty=l1)',\n",
       "  -0.7327764772752202),\n",
       " ('LogisticRegression(MaxAbsScaler(DecisionTreeClassifier(XGBClassifier(MaxAbsScaler(DecisionTreeClassifier(DecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=17, DecisionTreeClassifier__min_samples_split=4), DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=19, DecisionTreeClassifier__min_samples_split=17)), XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=12, XGBClassifier__n_estimators=100, XGBClassifier__nthread=1, XGBClassifier__subsample=0.15000000000000002), DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=19, DecisionTreeClassifier__min_samples_split=17)), LogisticRegression__C=1.0, LogisticRegression__dual=False, LogisticRegression__penalty=l1)',\n",
       "  -0.7328113343340186),\n",
       " ('LogisticRegression(MaxAbsScaler(DecisionTreeClassifier(XGBClassifier(MaxAbsScaler(DecisionTreeClassifier(DecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=17, DecisionTreeClassifier__min_samples_split=12), DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=19, DecisionTreeClassifier__min_samples_split=17)), XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=2, XGBClassifier__min_child_weight=12, XGBClassifier__n_estimators=100, XGBClassifier__nthread=1, XGBClassifier__subsample=0.15000000000000002), DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=19, DecisionTreeClassifier__min_samples_split=17)), LogisticRegression__C=1.0, LogisticRegression__dual=False, LogisticRegression__penalty=l1)',\n",
       "  -0.7328113343340186),\n",
       " ('LogisticRegression(XGBClassifier(MinMaxScaler(MaxAbsScaler(DecisionTreeClassifier(DecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=17, DecisionTreeClassifier__min_samples_split=4), DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=19, DecisionTreeClassifier__min_samples_split=17))), XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=6, XGBClassifier__n_estimators=100, XGBClassifier__nthread=1, XGBClassifier__subsample=0.05), LogisticRegression__C=1.0, LogisticRegression__dual=False, LogisticRegression__penalty=l1)',\n",
       "  -0.73303621867557),\n",
       " ('LogisticRegression(XGBClassifier(MinMaxScaler(MaxAbsScaler(DecisionTreeClassifier(DecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=17, DecisionTreeClassifier__min_samples_split=4), DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=5, DecisionTreeClassifier__min_samples_split=17))), XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=6, XGBClassifier__n_estimators=100, XGBClassifier__nthread=1, XGBClassifier__subsample=0.05), LogisticRegression__C=1.0, LogisticRegression__dual=False, LogisticRegression__penalty=l1)',\n",
       "  -0.73303621867557),\n",
       " ('LogisticRegression(XGBClassifier(MinMaxScaler(MaxAbsScaler(DecisionTreeClassifier(DecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=17, DecisionTreeClassifier__min_samples_split=18), DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=5, DecisionTreeClassifier__min_samples_split=17))), XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=6, XGBClassifier__n_estimators=100, XGBClassifier__nthread=1, XGBClassifier__subsample=0.05), LogisticRegression__C=1.0, LogisticRegression__dual=False, LogisticRegression__penalty=l1)',\n",
       "  -0.73303621867557),\n",
       " ('XGBClassifier(MaxAbsScaler(DecisionTreeClassifier(DecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=17, DecisionTreeClassifier__min_samples_split=4), DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=19, DecisionTreeClassifier__min_samples_split=17)), XGBClassifier__learning_rate=0.1, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=16, XGBClassifier__n_estimators=100, XGBClassifier__nthread=1, XGBClassifier__subsample=0.8)',\n",
       "  -0.7330416062390225),\n",
       " ('XGBClassifier(MaxAbsScaler(DecisionTreeClassifier(DecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=17, DecisionTreeClassifier__min_samples_split=4), DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=17, DecisionTreeClassifier__min_samples_split=4)), XGBClassifier__learning_rate=0.1, XGBClassifier__max_depth=3, XGBClassifier__min_child_weight=16, XGBClassifier__n_estimators=100, XGBClassifier__nthread=1, XGBClassifier__subsample=0.8)',\n",
       "  -0.7330416062390225)]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator_tuples = [(est, info['internal_cv_score']) for est, info in tpot.evaluated_individuals_.items()]\n",
    "estimator_tuples = sorted(estimator_tuples, key=lambda x: x[1], reverse=True)\n",
    "top_10_estimators = estimator_tuples[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tpot.builtins import StackingEstimator\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Average CV score on the training set was:-0.7326581163228116\n",
    "exported_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=DecisionTreeClassifier(criterion=\"entropy\", max_depth=2, min_samples_leaf=17, min_samples_split=4)),\n",
    "    StackingEstimator(estimator=DecisionTreeClassifier(criterion=\"entropy\", max_depth=2, min_samples_leaf=19, min_samples_split=17)),\n",
    "    StackingEstimator(estimator=XGBClassifier(learning_rate=0.01, max_depth=2, min_child_weight=12, n_estimators=100, nthread=1, subsample=0.15000000000000002)),\n",
    "    StackingEstimator(estimator=GaussianNB()),\n",
    "    StackingEstimator(estimator=DecisionTreeClassifier(criterion=\"entropy\", max_depth=2, min_samples_leaf=19, min_samples_split=17)),\n",
    "    MaxAbsScaler(),\n",
    "    VarianceThreshold(threshold=0.005),\n",
    "    LogisticRegression(C=1.0, dual=False, penalty=\"l1\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/renier.botha/anaconda3/envs/mobile_money/lib/python3.7/site-packages/sklearn/model_selection/_split.py:629: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n",
      "/Users/renier.botha/anaconda3/envs/mobile_money/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/renier.botha/anaconda3/envs/mobile_money/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/renier.botha/anaconda3/envs/mobile_money/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/renier.botha/anaconda3/envs/mobile_money/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.74571421 -0.75856724 -0.75915338]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/renier.botha/anaconda3/envs/mobile_money/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/renier.botha/anaconda3/envs/mobile_money/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cv_score = cross_val_score(best_model, \n",
    "                           X_train,\n",
    "                           y_train, \n",
    "                           cv=StratifiedKFold(random_state=420, shuffle=True), \n",
    "                           scoring='neg_log_loss')\n",
    "print(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/renier.botha/anaconda3/envs/mobile_money/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/renier.botha/anaconda3/envs/mobile_money/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       "                ('stackingestimator-1',\n",
       "                 StackingEstimator(estimator=BernoulliNB(alpha=1.0,\n",
       "                                                         binarize=0.0,\n",
       "                                                         class_prior=None,\n",
       "                                                         fit_prior=True))),\n",
       "                ('maxabsscaler-1', MaxAbsScaler(copy=True)),\n",
       "                ('selectpercentile',\n",
       "                 SelectPercentile(percentile=92,\n",
       "                                  score_func=<function f_classif at 0x11e98c1e0>)),...\n",
       "                                                                        validation_fraction=0.1,\n",
       "                                                                        verbose=0,\n",
       "                                                                        warm_start=False))),\n",
       "                ('maxabsscaler-2', MaxAbsScaler(copy=True)),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=0.1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/renier.botha/anaconda3/envs/mobile_money/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/renier.botha/anaconda3/envs/mobile_money/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/renier.botha/anaconda3/envs/mobile_money/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/renier.botha/anaconda3/envs/mobile_money/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/renier.botha/anaconda3/envs/mobile_money/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/renier.botha/anaconda3/envs/mobile_money/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/renier.botha/anaconda3/envs/mobile_money/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "cv_preds = cross_val_predict(best_model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import make_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_financial_services</th>\n",
       "      <th>other_only</th>\n",
       "      <th>mm_only</th>\n",
       "      <th>mm_plus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2352</th>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.042567</td>\n",
       "      <td>0.955711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8208</th>\n",
       "      <td>0.050109</td>\n",
       "      <td>0.040072</td>\n",
       "      <td>0.104052</td>\n",
       "      <td>0.805766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2785</th>\n",
       "      <td>0.004545</td>\n",
       "      <td>0.022643</td>\n",
       "      <td>0.081706</td>\n",
       "      <td>0.891106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2967</th>\n",
       "      <td>0.322540</td>\n",
       "      <td>0.626212</td>\n",
       "      <td>0.019940</td>\n",
       "      <td>0.031308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.003893</td>\n",
       "      <td>0.149355</td>\n",
       "      <td>0.846186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      no_financial_services  other_only   mm_only   mm_plus\n",
       "2352               0.000317    0.001405  0.042567  0.955711\n",
       "8208               0.050109    0.040072  0.104052  0.805766\n",
       "2785               0.004545    0.022643  0.081706  0.891106\n",
       "2967               0.322540    0.626212  0.019940  0.031308\n",
       "1697               0.000566    0.003893  0.149355  0.846186"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = model.predict_proba(X_test)\n",
    "sub_df = make_sub(probs)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv('../../data/submissions/tpot_target_encoding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mobile_money]",
   "language": "python",
   "name": "conda-env-mobile_money-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
